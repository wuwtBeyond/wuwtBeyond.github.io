https://juejin.cn/post/6844904014526545934

flink vs spark streaming 对比？
Flink 是标准的实时处理引擎，基于事件驱动。而 Spark Streaming 是微批（Micro-Batch）的模型

架构不同
flink的角色有jobmanager/taskmanager/slot，同时flink根据用户用户提交的代码生成streamgraph，进过优化
生成jobgraph，jobgraph也是flink ui所看到的拓扑图，jobmanager会根据jobgraph生成execution graph，
execution graph是最核心的数据结构，job manager会根据execution graph调度任务

时间机制
flink支持多种时间类型，包括处理时间、进入时间、事件时间，同时支持watermark处理滞后数据

flink集群角色和作用是什么？
jobmanager: 集群中的master，负责接收job、协调检查点、故障恢复等，同时管理flink节点taskmanager
taskmanager: 实际干活的，每个taskmanager负责管理其所在节点的资源信息，如内存、磁盘、网络，在启动的时候向jobmanager汇报
client: flink提交程序的客户端，当提交一个flink程序时，首先创建一个client，该client首先对代码进行预处理，然后提交给jobmanager

flink ha机制是什么?
standalone模式：依赖zk实现ha
在 Zookeeper 的帮助下，一个 Standalone 的 Flink 集群会同时有多个活着的 JobManager，其中只有一个处于工作状态，其他处于 Standby 状态。
当工作中的 JobManager 失去连接后（如宕机或 Crash），Zookeeper 会从 Standby 中选举新的 JobManager 来接管 Flink 集群。
yarn cluster模式：
依靠 Yarn 本身来对 JobManager 做 HA，完全依靠着 Yarn 中的 ResourceManager实现故障恢复。

介绍一下fink的slot，它的作用是什么？
taskmanager是实际负责计算的worker，taskmanager是一个jvm进程，并会以独立的线程来执行一个task或多个subtask。
为了控制一个taskmanager能接收线程的最大数量，flink提出slot的概念来作限制。slot会均分jvm的内存，避免不同slot的线程任务相互竞争内存资源，实现内存隔离，但不会实现cpu隔离。

flink的槽slot和并行度parallelism有什么关系？
flink程序最大并行度等于slot的最大可用数量，即taskmanager的数量乘以每个taskmanager上slot的数量

flink之所以有这么高的吞吐量的原因，你认为有什么？
为了更高效地分布式执行，flink会尽可能的将多并行度的上下游算子的实例链接在一起，也就是尽可能的将上下游算子放在同一个slot中执行，这样做的好处是
减少线程之间的切换，减少数据的序列化和反序列化，减少数据的io交互，减少延迟的同时提高整体的吞吐量。

flink形成operator chain算子链的条件是什么？
需要基本的一个保证是算子链不会改变拓扑结构。
1、上下游的并行度一致
2、下游节点的入度为1 （也就是说下游节点没有来自其他节点的输入）
3、上下游节点都在同一个 slot group 中（下面会解释 slot group）
4、下游节点的 chain 策略为 ALWAYS（可以与上下游链接，map、flatmap、filter等默认是ALWAYS）
5、上游节点的 chain 策略为 ALWAYS 或 HEAD（只能与下游链接，不能与上游链接，Source默认是HEAD）
6、两个节点间数据分区方式是 forward
7、用户没有禁用 chain

谈下项目中使用的flink常用算子及上下游算子间的分区策略？
分区策略是指一条数据如何从上游算子发给下游算子，flink默认实现8种分区策略，在flink ui上也可以看到
注意：flink改变并行度，默认是reblance的分区策略，这种可能会带来数据乱序执行的问题，线上环境出过类似问题，印象深刻

globalpartitioner: 数据会被分发到下游算子的第一个实例执行
shufflepartitioner: 数据会被随机分发下游算子的一个实例中执行
reblancepartitioner: 数据会被循环发送到下游的每一个算子执行
rescalepartitioner: 根据上下游算子的并行度，循环输出到下游算子
broadcastpartitioner: 广播方式发往下游每个算子
forwardpartitioner: 数据会被分发到下游本地算子执行，要求上下游算子并行度一致
keygroupstreampartitioner: 将数据按key的hash值发往下游算子执行
custompartitionerwrapper: 自定义分区器，实现partitioner接口 

map：常用于转换操作  reblance分区
flatmap: 一对多输出 
filter: 过滤器
keyby: 
window:
union: 

flink的分布式缓存是什么？
依托于hdfs，把文件放到hdfs，每一个taskmanager中的任务去hdfs拉取文件。

什么是广播变量？
首先广播变量是只读的，不允许修改
Broadcast是一份存储在TaskManager内存中的只读的缓存数据
1、从clinet端将一份需要反复使用的数据封装到广播变量中，分发到每个TaskManager的内存中保存
2、TaskManager中的所有Slot所管理的线程在执行task的时候如果需要用到该变量就从TaskManager的内存中读取数据，达到数据共享的效果

flink中的窗口是什么？
flink支持两种划分窗口的方式，time和count
tumbling-window  滚动窗口
sliding-window  滑动窗口
time-tumbling-window 无重叠数据的时间窗口，设置方式举例：timeWindow(Time.seconds(5))
time-sliding-window 有重叠数据的时间窗口，设置方式举例：timeWindow(Time.seconds(5), Time.seconds(3))
count-tumbling-window无重叠数据的数量窗口，设置方式举例：countWindow(5)
count-sliding-window 有重叠数据的数量窗口，设置方式举例：countWindow(5,3)

flink中的checkpoint是怎么做的？
flink在计算的过程中需要存储中间状态来避免数据丢失和故障恢复，flink提供三种状态存储方式，MemoryStateBackend、FsStateBackend、RocksDBStateBackend

flink中的时间概念有哪几种类型？watermark有什么作用？



说下flink生产环境遇到的问题以及如何解决的？
