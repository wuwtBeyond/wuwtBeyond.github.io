mysql三种日志总结  binlog redo undo 看懂就能明白 https://my.oschina.net/javazhiyin/blog/4517915

mysql事务的流程 https://www.imooc.com/article/247122

InnoDB引擎支持事务，进而有了undo/redo日志，binlog日志是mysql server的日志
https://blog.csdn.net/qq_42651904/article/details/104549645
一条SQL语句更新的流程？
1、加载磁盘文件到 Buffer Pool 缓冲池中
2、将未修改的数据写入undo日志中，作用：便于数据回滚
3、更新缓存Buffer Pool 的数据
4、写入redo日志，redo日志则是记录了对哪个数据做了修改
5、准备提交事务将redo日志写入磁盘
6、准备提交事务将binlog日志写入磁盘（binlog日志记录对哪个数据做了修改，修改结果是什么）
7、将binlog更新的文件名和更新文件的位置写入redo，并在redo log添加commit标记
8、IO线程随机将 Buffer Pool 缓冲池中的数据刷入磁盘
https://blog.csdn.net/qq_39088066/article/details/102651838
1、undo日志
当更新一条数据的时候，将未修改的数据写入undo日志中 作用：便于数据回滚
2、redo日志
redo日志记录了修改后的值，防止数据丢失
假如我们修改了Buffer Pool缓存中的值，还没有来得及刷新磁盘中的数据，数据库宕机了，那么Buffer Pool缓存中的数据丢失不是让磁盘中这一条数据成了脏数据吗？
因为有redo日志，可以通过redo日志恢复所以是不要紧的。
redo可以设置以下几种刷盘策略，他是通过参数innodb_flush_log_at_trx_commit配置的
当参数为0时，提交事务不会将redo日志强制刷入磁盘
当参数为1时，提交事务成功一定会将redo日志写入磁盘
当参数为2时，提交事务时将redo日志写入os cache缓存中，1秒后写入磁盘
3、binlog日志
binlog日志也有参数控制刷盘策略，sync_binlog，默认为0表示不是直接写入磁盘，也是先写入os cache缓存中，所以这里建议是吧sync_binlog参数设置为1，强制在提交事务的时候写入磁盘
应用场景：故障恢复
应用场景：主从同步
4、为什么最后redo日志要写入commit标记？
为了保证binlog日志和redo日志的一致性
假设redo日志刚刚写入磁盘文件后mysql宕机了，不会因为redo日志有数据而binlog没有数据产生数据不一致问题，因为redo日志文件没有最终标记commit，所以这次事务是提交失败的
5、redo log和bin log的区别？
redo log是物理日志，记录了在数据页上做了什么修改；bin log是逻辑日志，记录了sql的原始逻辑
redo log是InnoDB引擎特有的，bin log是mysql server层实现的，所有引擎都会有
redo log是循环写的，有固定空间，bin log是追加写入的,日志文件会切分固定块大小
6、可不可以只要bin log，不要redo log?
不可以
redo log 是循环写不能保证所有的历史数据，这些历史数据只能在 binlog 中找到；
binlog 是高可用的基础，高可用的实现原理就是 binlog 复制。
7、事务执行期间，还未提交，如果发生crash，redo log丢失，是否会导致主备不一致？
不会
这时候 binlog 也还在 binlog cache 里，没发给备库，crash 以后 redo log 和 binlog 都没有了，从业务角度看这个事务也没有提交，所以数据是一致的。

mysql慢查询
1，cpu负载高  一般查询语句带有计算逻辑，检查
2，io负载高  一般是查询了没建索引的列

可以设置查询时长，过滤查询时长特别长的SQL

有些SQL虽然出现在慢查询日志中，但未必是其本身的性能问题，可能是因为锁等待，服务器压力高等等。
需要分析SQL语句真实的执行计划，而不是看重新执行一遍SQL时，花费了多少时间
由自带的慢查询日志或者开源的慢查询系统定位到具体的出问题的SQL，然后使用Explain工具来逐步调优
了解 MySQL 在执行这条数据时的一些细节，比如是否进行了优化、是否使用了索引等等。
基于 Explain 的返回结果我们就可以根据 MySQL 的执行细节进一步分析是否应该优化搜索、怎样优化索引。

关于sql调优，个人特别推荐美团点评技术团队的几点总结

最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整；
尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录；
索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’);
尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。


基于本文的思路，关于SQL慢查询的解决可以按照以下的步骤执行：
1. 打开慢日志查询，确定是否有SQL语句占用了过多资源，如果是，在不改变业务原意的前提下，对insert、group by、order by、join等语句进行优化。
2. 考虑调整MySQL的系统参数： innodb_buffer_pool_size、innodb_log_file_size、table_cache等。
3. 确定是否是因为高并发引起行锁的超时问题。
4. 如果数据量过大，需要考虑进一步的分库分表

生产环境碰到的实际问题：
线上数据库建立索引导致锁表